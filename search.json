[{"path":"/AGENTS.html","id":"package-overview","dir":"","previous_headings":"","what":"Package Overview","title":"NA","text":"anvil code transformation framework similar jax R. currently support jit compilation automatic differentiation.","code":""},{"path":[]},{"path":"/AGENTS.html","id":"build-and-install","dir":"","previous_headings":"Development Commands","what":"Build and Install","title":"NA","text":"","code":"# Load the package for development devtools::load_all()  # Install the package devtools::install()  # Build the package (creates tar.gz file) devtools::build()"},{"path":"/AGENTS.html","id":"testing","dir":"","previous_headings":"Development Commands","what":"Testing","title":"NA","text":"","code":"# Run all tests devtools::test()  # Run a specific test file testthat::test_file(\"tests/testthat/test-constant.R\")"},{"path":"/AGENTS.html","id":"documentation","dir":"","previous_headings":"Development Commands","what":"Documentation","title":"NA","text":"","code":"# Generate documentation from roxygen comments devtools::document()"},{"path":"/AGENTS.html","id":"check","dir":"","previous_headings":"Development Commands","what":"Check","title":"NA","text":"","code":"# Run checks for CRAN compliance devtools::check()"},{"path":"/AGENTS.html","id":"development-practices","dir":"","previous_headings":"","what":"Development Practices","title":"NA","text":"Use S7 (object-oriented system) defining types classes. Follow established pattern adding new operations types Add tests tests/testthat/ Document functions roxygen2 comments","code":""},{"path":"/AGENTS.html","id":"project-information","dir":"","previous_headings":"","what":"Project Information","title":"NA","text":"stablehlo (jit interpretation rules) uses 0-based indexing, anvil uses 1-based indexing. implementing jit interpretation rule, convert indices subtracting 1.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 anvil authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/autodiff-modes.html","id":"forward-mode-autodiff","dir":"Articles","previous_headings":"","what":"Forward mode autodiff","title":"Autodiff Modes","text":"case, build jacobian column column. .e., calculate partial derivative \\(f\\) respect \\(b_1\\), \\(b_2\\), etc. practice, start multiplying \\(\\frac{\\partial z}{\\partial b}\\) one hot vector \\(e_1\\) (.e., first column identity matrix). Writing matrices, get: \\[ \\begin{bmatrix} \\frac{\\partial z_1}{\\partial b_1} & \\cdots & \\frac{\\partial z_1}{\\partial b_p} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial z_l}{\\partial b_1} & \\cdots & \\frac{\\partial z_l}{\\partial b_p} \\end{bmatrix}\\times \\begin{bmatrix} 1 \\\\ \\vdots \\\\ 0 \\end{bmatrix}= \\begin{bmatrix} \\frac{\\partial z_1}{\\partial b_1} \\\\ \\vdots \\\\ \\frac{\\partial z_l}{\\partial b_1} \\end{bmatrix} \\] give us intermediate matrix \\(u \\\\R^{l \\times 1}\\). get final result, need multiply jacobian \\(y\\) respect \\(z\\) \\(u\\). \\[ \\begin{bmatrix} \\frac{\\partial y_1}{\\partial b_1} \\\\ \\vdots \\\\ \\frac{\\partial y_m}{\\partial b_1} \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial y_1}{\\partial z_1} & \\cdots & \\frac{\\partial y_1}{\\partial z_l} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial y_m}{\\partial z_1} & \\cdots & \\frac{\\partial y_m}{\\partial z_l} \\end{bmatrix} \\times \\begin{bmatrix} u_1 \\\\ \\vdots \\\\ u_l \\end{bmatrix} \\] Note – mathematically – course multiply single unity vector, whole identity matrix. reason done, memory costs computational complexity. first step forward mode AD multiply matrix size \\(l \\times p\\) matrix size \\(p \\times 1\\). result matrix size \\(l \\times 1\\). multiply identity matrix, start matrix size \\(p \\times p\\) first intermediate result matrix size \\(l \\times p\\). , issue, even single unity vector intermediate jacobian size \\(l \\times p\\), another one size \\(p \\times p\\) issue? reason , jacobian size \\(l \\times p\\) never stored memory, whereas intermediate value size \\(p \\times p\\) stored.","code":""},{"path":"/articles/autodiff-modes.html","id":"reverse-mode-autodiff","dir":"Articles","previous_headings":"","what":"Reverse mode autodiff","title":"Autodiff Modes","text":"Instead building jacobian column column, build jacobian row row. .e., calculate partial derivative \\(f\\) respect \\(b_1\\), \\(b_2\\), etc. go forward mode reverse mode transposing jacobian \\(f\\) respect \\(z\\). \\[ \\frac{\\partial f}{\\partial b}^\\top = \\big[\\frac{\\partial f}{\\partial z} \\times \\frac{\\partial z}{\\partial b}\\big]^\\top= \\frac{\\partial z}{\\partial b}^\\top \\times \\frac{\\partial f}{\\partial z}^\\top \\] now multiply unity vector \\(r_i \\\\R^{1 \\times m}\\), determines respect output variable calculate jacobian, get: \\[ \\frac{\\partial f}{\\partial b_1}^\\top \\times r_1 = \\frac{\\partial z}{\\partial b_1}^\\top \\times \\frac{\\partial f}{\\partial z}^\\top \\times r_1 \\] full matrix notation, get: \\[ \\begin{bmatrix} \\frac{\\partial y_1}{\\partial b_1} \\\\ \\vdots \\\\ \\frac{\\partial y_1}{\\partial b_p} \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial z_1}{\\partial b_1} & \\cdots & \\frac{\\partial z_l}{\\partial b_1} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial z_1}{\\partial b_p} & \\cdots & \\frac{\\partial z_l}{\\partial b_p} \\end{bmatrix} \\times \\begin{bmatrix} \\frac{\\partial y_1}{\\partial z_1} & \\cdots & \\frac{\\partial y_m}{\\partial z_1} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial y_1}{\\partial z_l} & \\cdots & \\frac{\\partial y_m}{\\partial z_l} \\end{bmatrix} \\times \\begin{bmatrix} 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} \\] look closely last equation, see now, requires us first calculate forward pass, calculate backward pass. , want start rightmost multiplication, reduces computational complexity. rightmost multiplication involves derivative \\(f\\) respect temporary variables \\(z\\). Therefore, first need obtain values using forward pass. Now, first step, computational complexity \\(O(m \\times l)\\) second one \\(O(p \\times l)\\).","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Sebastian Fischer. Maintainer, author. Daniel Falbel. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Fischer S, Falbel D (2025). anvil: Framework R code transformations. R package version 0.0.0.9000, https://r-xla.github.io/anvil/.","code":"@Manual{,   title = {anvil: Framework for R code transformations},   author = {Sebastian Fischer and Daniel Falbel},   year = {2025},   note = {R package version 0.0.0.9000},   url = {https://r-xla.github.io/anvil/}, }"},{"path":"/index.html","id":"anvil","dir":"","previous_headings":"","what":"Framework for R code transformations","title":"Framework for R code transformations","text":"Composable code transformation framework R, allowing run numerical programs speed light. currently implements JIT compilation fast execution backward-mode automatic differentiation. Programs can run various hardware backends, including CPU GPU.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Framework for R code transformations","text":"","code":"pak::pak(\"r-xla/anvil\")"},{"path":"/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"Framework for R code transformations","text":", create standard R function. directly call function, first need wrap jit() call. resulting function called AnvilTensors – primary data type {anvil} – JIT compiled subsequently executed. automatic differentiation, can also obtain gradient f.","code":"library(anvil) f <- function(a, b, x) {   a * x + b } f_jit <- jit(f)  a <- nv_scalar(1.0) b <- nv_scalar(-2.0) x <- nv_scalar(3.0)  f_jit(a, b, x) #> AnvilTensor  #>  1.0000 #> [ CPUf32{} ] g_jit <- jit(gradient(f, wrt = c(\"a\", \"b\"))) g_jit(a, b, x) #> $a #> AnvilTensor  #>  3.0000 #> [ CPUf32{} ]  #>  #> $b #> AnvilTensor  #>  1.0000 #> [ CPUf32{} ]"},{"path":"/index.html","id":"main-features","dir":"","previous_headings":"","what":"Main Features","title":"Framework for R code transformations","text":"Gradients functions scalar outputs supported. Code JIT compiled single kernel. Runs various hardware, including CPU GPU. package written almost entirely R. easy add new primitives. possible add new transformations, .k.. interpretation rules.","code":""},{"path":"/index.html","id":"acknowledgments","dir":"","previous_headings":"","what":"Acknowledgments","title":"Framework for R code transformations","text":"work supported MaRDI. JAX, especially autodidax tutorial. microjax project. JIT compilation, leverage OpenXLA project.","code":""},{"path":"/reference/data_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Tensor Data Types — data_types","title":"Tensor Data Types — data_types","text":"Data types tensors: dt_i1: boolean. dt_i{8, 16, 32, 64}: signed integer. dt_ui{8, 16, 32, 64}: unsigned integer. dt_f{32, 64}: float.","code":""},{"path":"/reference/gradient.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of a function — gradient","title":"Gradient of a function — gradient","text":"Compute gradient function using reverse mode automatic differentiation. Output must 0-dimensional tensor.","code":""},{"path":"/reference/gradient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of a function — gradient","text":"","code":"gradient(f, wrt = NULL)"},{"path":"/reference/gradient.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of a function — gradient","text":"f (function) wrt (character()) Names arguments differentiate respect . NULL, compute gradients w.r.t. differentiable arguments.","code":""},{"path":"/reference/gradient.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of a function — gradient","text":"(function)","code":""},{"path":"/reference/jit.html","id":null,"dir":"Reference","previous_headings":"","what":"JIT compile a function — jit","title":"JIT compile a function — jit","text":"Convert function JIT compiled function.","code":""},{"path":"/reference/jit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"JIT compile a function — jit","text":"","code":"jit(f, static = character())"},{"path":"/reference/jit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"JIT compile a function — jit","text":"f (function) Function compile. static (character()) parameters f static.","code":""},{"path":"/reference/jit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"JIT compile a function — jit","text":"(function)","code":""},{"path":"/reference/nv_binary_ops.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary Operations — nv_binary_ops","title":"Binary Operations — nv_binary_ops","text":"Binary operations tensors.","code":""},{"path":"/reference/nv_binary_ops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binary Operations — nv_binary_ops","text":"","code":"nv_add(lhs, rhs)  nv_mul(lhs, rhs)  nv_sub(lhs, rhs)  nv_div(lhs, rhs)"},{"path":"/reference/nv_binary_ops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binary Operations — nv_binary_ops","text":"lhs (nv_tensor) rhs (nv_tensor)","code":""},{"path":"/reference/nv_binary_ops.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binary Operations — nv_binary_ops","text":"nv_tensor","code":""},{"path":"/reference/nv_broadcast_tensors.html","id":null,"dir":"Reference","previous_headings":"","what":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","title":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","text":"Broadcast tensors common shape.","code":""},{"path":"/reference/nv_broadcast_tensors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","text":"","code":"nv_broadcast_tensors(...)"},{"path":"/reference/nv_broadcast_tensors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","text":"... (list() nv_tensor)","code":""},{"path":"/reference/nv_broadcast_tensors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","text":"(list() nv_tensor)","code":""},{"path":"/reference/nv_broadcast_tensors.html","id":"broadcasting-rules","dir":"Reference","previous_headings":"","what":"Broadcasting Rules","title":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","text":"follow standard NumPy broadcasting rules: tensors different numbers dimensions, prepend 1s shape smaller tensor. dimensions, : sizes , nothing. One tensors size 1, expand size tensor. sizes different neither 1, raise error.","code":""},{"path":"/reference/nv_broadcast_to.html","id":null,"dir":"Reference","previous_headings":"","what":"Broadcast — nv_broadcast_to","title":"Broadcast — nv_broadcast_to","text":"Broadcast","code":""},{"path":"/reference/nv_broadcast_to.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Broadcast — nv_broadcast_to","text":"","code":"nv_broadcast_to(x, shape)"},{"path":"/reference/nv_broadcast_to.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Broadcast — nv_broadcast_to","text":"x (nv_tensor) shape (integer()) Output shape.","code":""},{"path":"/reference/nv_broadcast_to.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Broadcast — nv_broadcast_to","text":"(nv_tensor)","code":""},{"path":"/reference/nv_dtype.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a TensorDataType — nv_dtype","title":"Create a TensorDataType — nv_dtype","text":"Create stablehlo::TensorDataType.","code":""},{"path":"/reference/nv_dtype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a TensorDataType — nv_dtype","text":"","code":"nv_dtype(x)"},{"path":"/reference/nv_dtype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a TensorDataType — nv_dtype","text":"x () Object convertible stablehlo::TensorDataType (via stablehlo::as_dtype)","code":""},{"path":"/reference/nv_dtype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a TensorDataType — nv_dtype","text":"stablehlo::TensorDataType","code":""},{"path":"/reference/nv_matmul.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix Multiplication — nv_matmul","title":"Matrix Multiplication — nv_matmul","text":"Matrix multiplication two tensors.","code":""},{"path":"/reference/nv_matmul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix Multiplication — nv_matmul","text":"","code":"nv_matmul(lhs, rhs)"},{"path":"/reference/nv_matmul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix Multiplication — nv_matmul","text":"lhs (nv_tensor) rhs (nv_tensor)","code":""},{"path":"/reference/nv_matmul.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix Multiplication — nv_matmul","text":"nv_tensor","code":""},{"path":"/reference/nv_matmul.html","id":"shapes","dir":"Reference","previous_headings":"","what":"Shapes","title":"Matrix Multiplication — nv_matmul","text":"lhs: (b1, ..., bk, m, n) rhs: (b1, ..., bk, n, p) output: (b1, ..., bk, m, p)","code":""},{"path":"/reference/nv_matmul.html","id":"broadcasting","dir":"Reference","previous_headings":"","what":"Broadcasting","title":"Matrix Multiplication — nv_matmul","text":"dimensions last two broadcasted.","code":""},{"path":"/reference/nv_reduce_ops.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduction Operators — nv_reduce_ops","title":"Reduction Operators — nv_reduce_ops","text":"Reduce tensor along specified dimensions.","code":""},{"path":"/reference/nv_reduce_ops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduction Operators — nv_reduce_ops","text":"","code":"nv_reduce_sum(operand, dims, drop = TRUE)"},{"path":"/reference/nv_reduce_ops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduction Operators — nv_reduce_ops","text":"operand (nv_tensor) tensor. dims (integer()) dimensions along reduce. drop (logical(1)) Whether drop reduced dimensions.","code":""},{"path":"/reference/nv_tensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Tensor — nv_tensor","title":"Tensor — nv_tensor","text":"Create tensor.","code":""},{"path":"/reference/nv_tensor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tensor — nv_tensor","text":"","code":"nv_tensor(data, dtype = NULL, platform = NULL, shape = NULL)  nv_scalar(data, dtype = NULL, platform = NULL)  nv_empty(dtype, shape, platform = NULL)"},{"path":"/reference/nv_tensor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tensor — nv_tensor","text":"data () Object convertible PJRTBuffer. dtype (NULL | character(1) | stablehlo::TensorDataType) One pred, i8, i16, i32, i64, ui8, ui16, ui32, ui64, f32, f64 stablehlo::TensorDataType. default (NULL) uses f32 numeric data, i32 integer data, pred logical data. platform (character(1)) platform name tensor (\"cpu\", \"cuda\", \"metal\"). Default use CPU, unless data already PJRTBuffer. can change default setting PJRT_PLATFORM environment variable. shape (NULL | integer()) Shape. default (NULL) infer data possible. Note nv_tensor interpretes length 1 vectors shape (1). create \"scalar\" dimension (), use nv_scalar.","code":""},{"path":"/reference/nv_tensor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tensor — nv_tensor","text":"(AnvilTensor)","code":""},{"path":"/reference/nv_tensor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tensor — nv_tensor","text":"Internally calls pjrt_buffer.","code":""},{"path":"/reference/nv_transpose.html","id":null,"dir":"Reference","previous_headings":"","what":"Transpose — nv_transpose","title":"Transpose — nv_transpose","text":"Transpose tensor.","code":""},{"path":"/reference/nv_transpose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transpose — nv_transpose","text":"","code":"# S3 method for class '`anvil::Box`' t(x)  nv_transpose(x, permutation = NULL)"},{"path":"/reference/nv_transpose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transpose — nv_transpose","text":"x (nv_tensor) permutation (integer() | NULl) Permutation dimensions. NULL (default), reverses dimensions.","code":""},{"path":"/reference/nv_transpose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transpose — nv_transpose","text":"nv_tensor","code":""},{"path":"/reference/nv_unary_ops.html","id":null,"dir":"Reference","previous_headings":"","what":"Unary Operations — nv_unary_ops","title":"Unary Operations — nv_unary_ops","text":"Unary operations tensors.","code":""},{"path":"/reference/nv_unary_ops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unary Operations — nv_unary_ops","text":"","code":"nv_neg(operand)"},{"path":"/reference/nv_unary_ops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unary Operations — nv_unary_ops","text":"operand (nv_tensor)","code":""},{"path":"/reference/nv_unary_ops.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unary Operations — nv_unary_ops","text":"nv_tensor","code":""},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. pjrt platform stablehlo is_dtype tengen as_array, as_raw, device, ndims, shape","code":""}]
