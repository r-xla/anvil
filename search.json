[{"path":"/AGENTS.html","id":"package-overview","dir":"","previous_headings":"","what":"Package Overview","title":"NA","text":"anvil code transformation framework similar jax R. currently support jit compilation automatic differentiation.","code":""},{"path":[]},{"path":"/AGENTS.html","id":"build-and-install","dir":"","previous_headings":"Development Commands","what":"Build and Install","title":"NA","text":"","code":"# Load the package for development devtools::load_all()  # Install the package devtools::install()  # Build the package (creates tar.gz file) devtools::build()"},{"path":"/AGENTS.html","id":"testing","dir":"","previous_headings":"Development Commands","what":"Testing","title":"NA","text":"","code":"# Run all tests devtools::test()  # Run a specific test file testthat::test_file(\"tests/testthat/test-constant.R\")"},{"path":"/AGENTS.html","id":"documentation","dir":"","previous_headings":"Development Commands","what":"Documentation","title":"NA","text":"","code":"# Generate documentation from roxygen comments devtools::document()"},{"path":"/AGENTS.html","id":"check","dir":"","previous_headings":"Development Commands","what":"Check","title":"NA","text":"","code":"# Run checks for CRAN compliance devtools::check()"},{"path":"/AGENTS.html","id":"development-practices","dir":"","previous_headings":"","what":"Development Practices","title":"NA","text":"Use S7 (object-oriented system) defining types classes. Follow established pattern adding new operations types Add tests tests/testthat/ Document functions roxygen2 comments","code":""},{"path":"/AGENTS.html","id":"project-information","dir":"","previous_headings":"","what":"Project Information","title":"NA","text":"stablehlo (jit interpretation rules) uses 0-based indexing, anvil uses 1-based indexing. implementing jit interpretation rule, convert indices subtracting 1. rules-pullback.R file contains differentiation rules primitive operations. , grad gradient terminal output respect function’s output function return gradient terminal output respect inputs. tests file insts/extra-tests/test-primitives-pullback-torch.R","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 anvil authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/anvil.html","id":"the-anviltensor","dir":"Articles","previous_headings":"","what":"The AnvilTensor","title":"Get Started","text":"start introducing main data structure, AnvilTensor. essentially like R array, differences: supports data types, different precisions, well unsigned integers. tensor can live different platforms, CPU GPU. 0-dimensional tensors can used represent scalars. can create object R data types using nv_tensor friends functions. , create 0-dimensional tensor (.e., scalar) type int16 CPU. Note creation scalars, can also use nv_scalar shorthand skip specifying shape. can also create higher-dimensional tensors, example 2x3 CPU tensor type f32. , omit specifying platform datatype, default \"cpu\" \"f32\". Note default datatype depends input datatype. order convert AnvilTensor back regular R array, can use as_array() function. first, working AnvilTensors may feel bit cumbersome, directly apply functions like regular R arrays.","code":"library(anvil) set.seed(42) nv_tensor(1L, dtype = \"i16\", device = \"cpu\", shape = integer()) ## AnvilTensor  ##  1 ## [ CPUi16{} ] nv_scalar(1L, dtype = \"i16\", device = \"cpu\") ## AnvilTensor  ##  1 ## [ CPUi16{} ] x <- array(1:6, dim = c(2, 3)) nv_tensor(x) ## AnvilTensor  ##  1 3 5 ##  2 4 6 ## [ CPUi32{2x3} ] y <- nv_tensor(x, dtype = \"f32\") y ## AnvilTensor  ##  1.0000 3.0000 5.0000 ##  2.0000 4.0000 6.0000 ## [ CPUf32{2x3} ] as_array(y) ##      [,1] [,2] [,3] ## [1,]    1    3    5 ## [2,]    2    4    6 x + x ##      [,1] [,2] [,3] ## [1,]    2    6   10 ## [2,]    4    8   12 #y + y"},{"path":"/articles/anvil.html","id":"jit-compilation","dir":"Articles","previous_headings":"","what":"JIT Compilation","title":"Get Started","text":"order work AnvilTensors, need convert function want apply jit-compiled version via anvil::jit(). result operation AnvilTensor. can, course, jit-compile complex functions well. , define function takes data matrix X, weight vector beta scalar bias b, computes linear model output \\(y = X \\times \\beta + \\alpha\\). One current restriction {anvil} function re-compiled every unique combination inputs shapes, data-types, platforms. demonstrate , create slightly modified version linear_model. demonstrate , create little helper function creates example input data different numbers observations: , call function twice data shapes. can notice see \"compiling ...\" message first third time. , first time, function compiled XLA executable cached later reuse. second time, don’t execute R function , directly run cached XLA executable. executable contain “standard” R code, like cat() call, records operations applied AnvilTensors. now call function data different shapes, see function re-compiled. compilation step can take time, {anvil} therefore gives best results function called many times input shapes, data types, platforms, computation sufficiently large amortize compilation overhead. One common application scenario assumption holds iterative optimization algorithms.","code":"plus_jit <- jit(`+`) plus_jit(y, y) ## AnvilTensor  ##   2.0000  6.0000 10.0000 ##   4.0000  8.0000 12.0000 ## [ CPUf32{2x3} ] linear_model_r <- function(X, beta, alpha) {   X %*% beta + alpha }  linear_model <- jit(linear_model_r)  X <- nv_tensor(rnorm(6), dtype = \"f32\", shape = c(2, 3)) beta <- nv_tensor(rnorm(3), dtype = \"f32\", shape = c(3, 1)) alpha <- nv_scalar(rnorm(1), dtype = \"f32\")  linear_model(X, beta, alpha) ## AnvilTensor  ##   2.7911 ##  -1.1904 ## [ CPUf32{2x1} ] linear_model2 <- jit(function(X, beta, alpha) {   cat(\"compiling ...\\n\")   X %*% beta + alpha }) simul_data <- function(n, p) {   list(     X = nv_tensor(rnorm(n * p), dtype = \"f32\", shape = c(n, p)),     beta = nv_tensor(rnorm(p), dtype = \"f32\", shape = c(p, 1)),     alpha = nv_scalar(rnorm(1), dtype = \"f32\")   ) } do.call(linear_model2, simul_data(2, 3)) ## compiling ... ## AnvilTensor  ##   4.9640 ##  -0.1413 ## [ CPUf32{2x1} ] do.call(linear_model2, simul_data(2, 3)) ## AnvilTensor  ##   0.6140 ##  -2.5214 ## [ CPUf32{2x1} ] y_hat <- do.call(linear_model2, simul_data(4, 3)) ## compiling ..."},{"path":"/articles/anvil.html","id":"static-arguments","dir":"Articles","previous_headings":"JIT Compilation","what":"Static Arguments","title":"Get Started","text":"One feature {anvil} arguments jit-compiled functions need AnvilTensors. example, might want linear model without intercept term. , add logical argument with_bias function. need mark argument static, {anvil} knows treat regular R value instead AnvilTensor. can call function now without bias term:","code":"linear_model3 <- jit(function(X, beta, alpha = NULL, with_bias) {   if (with_bias) {     cat(\"Compiling without bias ...\\n\")     X %*% beta + alpha   } else {     cat(\"Compiling with bias ...\\n\")     X %*% beta   } }, static = \"with_bias\") linear_model3(X, beta, with_bias =  FALSE) ## Compiling with bias ... ## AnvilTensor  ##   2.8538 ##  -1.1277 ## [ CPUf32{2x1} ] linear_model3(X, beta, alpha, with_bias =  TRUE) ## Compiling without bias ... ## AnvilTensor  ##   2.7911 ##  -1.1904 ## [ CPUf32{2x1} ]"},{"path":"/articles/anvil.html","id":"nested-inputs-and-outputs","dir":"Articles","previous_headings":"JIT Compilation","what":"Nested Inputs and Outputs","title":"Get Started","text":"Static arguments work differently AnvilTensors function re-compiled new observed value static argument. Note also, inputs, well outputs, can also contain nested data structures contain AnvilTensors, although currently support (named) lists. far, implemented prediction step linear model. One core applications anvil implement learning algorithms, often need gradients, well control flow. start gradients.","code":"linear_model4 <- jit(function(inputs) {   list(y_hat = inputs[[1]] %*% inputs[[2]] + inputs[[3]]) }) linear_model4(list(X, beta, alpha)) ## $y_hat ## AnvilTensor  ##   2.7911 ##  -1.1904 ## [ CPUf32{2x1} ]"},{"path":"/articles/anvil.html","id":"automatic-differentiation","dir":"Articles","previous_headings":"","what":"Automatic Differentiation","title":"Get Started","text":"anvil, can easily obtain gradient function scalar-valued function using gradient(): Currently, vector-valued functions differentiated. , implement implement loss function linear model. now need target variables y, simulate data linear model:  Next, randomly initialize model parameters: can now define function prediction calculates loss. Note calling original R function prediction jit-compiled version. Using gradient() transformation, can automatically obtain gradient function model_loss respect arguments, specify. Finally, define update step weights using gradient descent. already allows us train linear model using gradient descent:  might seem like reasonable solution, continuously switches R interpreter XLA runtime. Moreover, allocate new tensors iteration weights. latter might big problem small models, can lead significant overhead working bigger tensors. Next, briefly address concept immutability anvil options work around .","code":"mse <- function(y_hat, y) {   mean((y_hat - y)^nv_scalar(2.0)) } beta <- rnorm(1) X <- matrix(rnorm(100), ncol = 1) alpha <- rnorm(1) y <- X %*% beta + alpha + rnorm(100, sd = 0.5) plot(X, y) X <- nv_tensor(X) y <- nv_tensor(y) beta_hat <- nv_tensor(rnorm(1), shape = c(1, 1), dtype = \"f32\") alpha_hat <- nv_scalar(rnorm(1), dtype = \"f32\") model_loss <- function(X, beta, alpha, y) {   y_hat <- linear_model_r(X, beta, alpha)   mse(y_hat, y) } model_loss_grad <- gradient(   model_loss,   wrt = c(\"beta\", \"alpha\") ) update_weights <- jit(function(X, beta, alpha, y, lr) {   lr <- nv_scalar(0.1)   grads <- model_loss_grad(X, beta, alpha, y)   beta_new <- beta - lr * grads$beta   alpha_new <- alpha - lr * grads$alpha   list(beta = beta_new, alpha = alpha_new) }) weights <- list(beta = beta_hat, alpha = alpha_hat) for (i in 1:100) {   weights <- update_weights(X, weights$beta, weights$alpha, y) }"},{"path":"/articles/anvil.html","id":"immutability","dir":"Articles","previous_headings":"","what":"Immutability","title":"Get Started","text":"Conceptually, whenever defining programs anvil, strictly following value semantics. means, -place modifications like updating array element conceptually impossible. dealing updating existing tensor, might either : 1. Updating AnvilTensor “lives within” jit-compiled function. 2. Updating AnvilTensor living R jit-compiled function. first category, function TODO demonstrated . thing note conceptually, -place update, creates new tensor, XLA compiler able optimize , ensuring unnecessary copies actually made. second category, can mark arguments jit-compiled function “donatable”. means, telling XLA runtime pass tensors marked donatable function, longer use R. XLA compiler therefore able reuse memory.","code":"# TODO # TODO"},{"path":"/articles/anvil.html","id":"control-flow","dir":"Articles","previous_headings":"Immutability","what":"Control Flow","title":"Get Started","text":"Earlier, already used R control flow train linear model. principle, three ways handle control-flow anvil: Embed jit-compiled functions inside R control-flow constructs, seen earlier. Embed R control flow inside jit-compiled function (also seen earlier linear model allowed optionally include bias term). Use special control-flow primitives provided anvil, nv_while() nv_if(). ’s best solution depends specific scenario. One thing aware usually don’t want R loops within jit-compiled function. , loop unrolled compilation, can lead large compilation times big executables. thing demonstrated far , choice either implement loop R, call jit-compiled function iteration, implement loop part jit-compiled function . advantage former allows including standard R code loop, can e.g. useful logging purposes. However, depending duration iteration, might significant overhead switching R compiled code. example, fit linear model using gradient descent. course, usually fit model solving normal equations directly, just demonstration purposes.","code":""},{"path":"/articles/autodiff-modes.html","id":"forward-mode-autodiff","dir":"Articles","previous_headings":"","what":"Forward mode autodiff","title":"Autodiff Modes","text":"case, build jacobian column column. .e., calculate partial derivative \\(f\\) respect \\(b_1\\), \\(b_2\\), etc. practice, start multiplying \\(\\frac{\\partial z}{\\partial b}\\) one hot vector \\(e_1\\) (.e., first column identity matrix). Writing matrices, get: \\[ \\begin{bmatrix} \\frac{\\partial z_1}{\\partial b_1} & \\cdots & \\frac{\\partial z_1}{\\partial b_p} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial z_l}{\\partial b_1} & \\cdots & \\frac{\\partial z_l}{\\partial b_p} \\end{bmatrix}\\times \\begin{bmatrix} 1 \\\\ \\vdots \\\\ 0 \\end{bmatrix}= \\begin{bmatrix} \\frac{\\partial z_1}{\\partial b_1} \\\\ \\vdots \\\\ \\frac{\\partial z_l}{\\partial b_1} \\end{bmatrix} \\] give us intermediate matrix \\(u \\\\R^{l \\times 1}\\). get final result, need multiply jacobian \\(y\\) respect \\(z\\) \\(u\\). \\[ \\begin{bmatrix} \\frac{\\partial y_1}{\\partial b_1} \\\\ \\vdots \\\\ \\frac{\\partial y_m}{\\partial b_1} \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial y_1}{\\partial z_1} & \\cdots & \\frac{\\partial y_1}{\\partial z_l} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial y_m}{\\partial z_1} & \\cdots & \\frac{\\partial y_m}{\\partial z_l} \\end{bmatrix} \\times \\begin{bmatrix} u_1 \\\\ \\vdots \\\\ u_l \\end{bmatrix} \\] Note – mathematically – course multiply single unity vector, whole identity matrix. reason done, memory costs computational complexity. first step forward mode AD multiply matrix size \\(l \\times p\\) matrix size \\(p \\times 1\\). result matrix size \\(l \\times 1\\). multiply identity matrix, start matrix size \\(p \\times p\\) first intermediate result matrix size \\(l \\times p\\). , issue, even single unity vector intermediate jacobian size \\(l \\times p\\), another one size \\(p \\times p\\) issue? reason , jacobian size \\(l \\times p\\) never stored memory, whereas intermediate value size \\(p \\times p\\) stored.","code":""},{"path":"/articles/autodiff-modes.html","id":"reverse-mode-autodiff","dir":"Articles","previous_headings":"","what":"Reverse mode autodiff","title":"Autodiff Modes","text":"Instead building jacobian column column, build jacobian row row. .e., calculate partial derivative \\(f\\) respect \\(b_1\\), \\(b_2\\), etc. go forward mode reverse mode transposing jacobian \\(f\\) respect \\(z\\). \\[ \\frac{\\partial f}{\\partial b}^\\top = \\big[\\frac{\\partial f}{\\partial z} \\times \\frac{\\partial z}{\\partial b}\\big]^\\top= \\frac{\\partial z}{\\partial b}^\\top \\times \\frac{\\partial f}{\\partial z}^\\top \\] now multiply unity vector \\(r_i \\\\R^{1 \\times m}\\), determines respect output variable calculate jacobian, get: \\[ \\frac{\\partial f}{\\partial b_1}^\\top \\times r_1 = \\frac{\\partial z}{\\partial b_1}^\\top \\times \\frac{\\partial f}{\\partial z}^\\top \\times r_1 \\] full matrix notation, get: \\[ \\begin{bmatrix} \\frac{\\partial y_1}{\\partial b_1} \\\\ \\vdots \\\\ \\frac{\\partial y_1}{\\partial b_p} \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial z_1}{\\partial b_1} & \\cdots & \\frac{\\partial z_l}{\\partial b_1} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial z_1}{\\partial b_p} & \\cdots & \\frac{\\partial z_l}{\\partial b_p} \\end{bmatrix} \\times \\begin{bmatrix} \\frac{\\partial y_1}{\\partial z_1} & \\cdots & \\frac{\\partial y_m}{\\partial z_1} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial y_1}{\\partial z_l} & \\cdots & \\frac{\\partial y_m}{\\partial z_l} \\end{bmatrix} \\times \\begin{bmatrix} 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} \\] look closely last equation, see now, requires us first calculate forward pass, calculate backward pass. , want start rightmost multiplication, reduces computational complexity. rightmost multiplication involves derivative \\(f\\) respect temporary variables \\(z\\). Therefore, first need obtain values using forward pass. Now, first step, computational complexity \\(O(m \\times l)\\) second one \\(O(p \\times l)\\).","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Sebastian Fischer. Maintainer, author. Daniel Falbel. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Fischer S, Falbel D (2025). anvil: Framework R code transformations. R package version 0.0.0.9000, https://r-xla.github.io/anvil/.","code":"@Manual{,   title = {anvil: Framework for R code transformations},   author = {Sebastian Fischer and Daniel Falbel},   year = {2025},   note = {R package version 0.0.0.9000},   url = {https://r-xla.github.io/anvil/}, }"},{"path":"/index.html","id":"anvil","dir":"","previous_headings":"","what":"Framework for R code transformations","title":"Framework for R code transformations","text":"Composable code transformation framework R, allowing run numerical programs speed light. currently implements JIT compilation fast execution backward-mode automatic differentiation. Programs can run various hardware backends, including CPU GPU.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Framework for R code transformations","text":"currently don’t CRAN release, need install package source. , need C++20 compiler, well libprotobuf protobuf-compiler.","code":"pak::pak(\"r-xla/anvil\")"},{"path":"/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"Framework for R code transformations","text":", create standard R function. directly call function, first need wrap jit() call. resulting function called AnvilTensors – primary data type {anvil} – JIT compiled subsequently executed. automatic differentiation, can also obtain gradient function.","code":"library(anvil) f <- function(a, b, x) {   a * x + b } f_jit <- jit(f)  a <- nv_scalar(1.0) b <- nv_scalar(-2.0) x <- nv_scalar(3.0)  f_jit(a, b, x) #> AnvilTensor  #>  1.0000 #> [ CPUf32{} ] g_jit <- jit(gradient(f, wrt = c(\"a\", \"b\"))) g_jit(a, b, x) #> $a #> AnvilTensor  #>  3.0000 #> [ CPUf32{} ]  #>  #> $b #> AnvilTensor  #>  1.0000 #> [ CPUf32{} ]"},{"path":"/index.html","id":"main-features","dir":"","previous_headings":"","what":"Main Features","title":"Framework for R code transformations","text":"Gradients functions scalar outputs supported. Code JIT compiled single kernel. Runs different hardware backends, including CPU GPU. package written almost entirely R. easy add new primitives. () possible add new transformations, .k.. interpretation rules.","code":""},{"path":"/index.html","id":"when-to-use-this-package","dir":"","previous_headings":"","what":"When to use this package?","title":"Framework for R code transformations","text":"{anvil} allows run certain types programs extremely fast, applies certain category problems. Specifically, suitable numerical algorithms, optimizing bayesian models, training neural networks generally numerical optimization. Another restriction {anvil} needs re-compile code new unique input shape. advantage, compiler can make memory optimizations, compilation overhead might problem fast running programs.","code":""},{"path":"/index.html","id":"acknowledgments","dir":"","previous_headings":"","what":"Acknowledgments","title":"Framework for R code transformations","text":"work supported MaRDI. JAX, especially autodidax tutorial. microjax project. JIT compilation, leverage OpenXLA project.","code":""},{"path":"/reference/Primitive.html","id":null,"dir":"Reference","previous_headings":"","what":"Primitive — Primitive","title":"Primitive — Primitive","text":"Primitive interpretation rule.","code":""},{"path":"/reference/Primitive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Primitive — Primitive","text":"","code":"Primitive(name)"},{"path":"/reference/Primitive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Primitive — Primitive","text":"name (character()) name primitive.","code":""},{"path":"/reference/Primitive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Primitive — Primitive","text":"(Primitive)","code":""},{"path":"/reference/data_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Tensor Data Types — data_types","title":"Tensor Data Types — data_types","text":"Data types tensors: dt_i1: boolean. dt_i{8, 16, 32, 64}: signed integer. dt_ui{8, 16, 32, 64}: unsigned integer. dt_f{32, 64}: float.","code":""},{"path":"/reference/gradient.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of a function — gradient","title":"Gradient of a function — gradient","text":"Compute gradient function using reverse mode automatic differentiation. Output must 0-dimensional tensor.","code":""},{"path":"/reference/gradient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of a function — gradient","text":"","code":"gradient(f, wrt = NULL)"},{"path":"/reference/gradient.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of a function — gradient","text":"f (function) wrt (character()) Names arguments differentiate respect . NULL, compute gradients w.r.t. differentiable arguments.","code":""},{"path":"/reference/gradient.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of a function — gradient","text":"(function)","code":""},{"path":"/reference/jit.html","id":null,"dir":"Reference","previous_headings":"","what":"JIT compile a function — jit","title":"JIT compile a function — jit","text":"Convert function JIT compiled function.","code":""},{"path":"/reference/jit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"JIT compile a function — jit","text":"","code":"jit(f, static = character(), device = NULL, cache_size = 100L)"},{"path":"/reference/jit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"JIT compile a function — jit","text":"f (function) Function compile. static (character()) parameters f static. device (NULL | character(1) | PJRTDevice) device use compiled function. default (NULL) uses PJRT_PLATFORM environment variable defaults \"cpu\". cache_size (integer(1)) size cache jit-compiled functions.","code":""},{"path":"/reference/jit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"JIT compile a function — jit","text":"(function)","code":""},{"path":"/reference/nv_binary_ops.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary Operations — nv_binary_ops","title":"Binary Operations — nv_binary_ops","text":"Binary operations tensors.","code":""},{"path":"/reference/nv_binary_ops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binary Operations — nv_binary_ops","text":"","code":"nv_add(lhs, rhs)  nv_mul(lhs, rhs)  nv_sub(lhs, rhs)  nv_div(lhs, rhs)  nv_pow(lhs, rhs)  nv_eq(lhs, rhs)  nv_ne(lhs, rhs)  nv_gt(lhs, rhs)  nv_ge(lhs, rhs)  nv_lt(lhs, rhs)  nv_le(lhs, rhs)  nv_max(lhs, rhs)  nv_min(lhs, rhs)  nv_remainder(lhs, rhs)  nv_and(lhs, rhs)  nv_or(lhs, rhs)  nv_xor(lhs, rhs)  nv_shift_left(lhs, rhs)  nv_shift_right_logical(lhs, rhs)  nv_shift_right_arithmetic(lhs, rhs)  nv_atan2(lhs, rhs)"},{"path":"/reference/nv_binary_ops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binary Operations — nv_binary_ops","text":"lhs (nv_tensor) rhs (nv_tensor)","code":""},{"path":"/reference/nv_binary_ops.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binary Operations — nv_binary_ops","text":"nv_tensor","code":""},{"path":"/reference/nv_broadcast_tensors.html","id":null,"dir":"Reference","previous_headings":"","what":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","title":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","text":"Broadcast tensors common shape.","code":""},{"path":"/reference/nv_broadcast_tensors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","text":"","code":"nv_broadcast_tensors(...)"},{"path":"/reference/nv_broadcast_tensors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","text":"... (nv_tensor) Tensors broadcast.","code":""},{"path":"/reference/nv_broadcast_tensors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","text":"(list() nv_tensor)","code":""},{"path":"/reference/nv_broadcast_tensors.html","id":"broadcasting-rules","dir":"Reference","previous_headings":"","what":"Broadcasting Rules","title":"Broadcast Tensors to a Common Shape — nv_broadcast_tensors","text":"follow standard NumPy broadcasting rules: tensors different numbers dimensions, prepend 1s shape smaller tensor. dimension, : sizes , nothing. one tensors size 1, expand corresponding size tensor. sizes different neither 1, raise error.","code":""},{"path":"/reference/nv_broadcast_to.html","id":null,"dir":"Reference","previous_headings":"","what":"Broadcast — nv_broadcast_to","title":"Broadcast — nv_broadcast_to","text":"Broadcast tensor given shape using NumPy broadcasting rules.","code":""},{"path":"/reference/nv_broadcast_to.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Broadcast — nv_broadcast_to","text":"","code":"nv_broadcast_to(operand, shape)"},{"path":"/reference/nv_broadcast_to.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Broadcast — nv_broadcast_to","text":"operand (nv_tensor) Operand. shape (integer()) Output shape.","code":""},{"path":"/reference/nv_broadcast_to.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Broadcast — nv_broadcast_to","text":"(nv_tensor)","code":""},{"path":"/reference/nv_convert.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Tensor to Different Data Type — nv_convert","title":"Convert Tensor to Different Data Type — nv_convert","text":"Convert tensor different data type.","code":""},{"path":"/reference/nv_convert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Tensor to Different Data Type — nv_convert","text":"","code":"nv_convert(operand, dtype)"},{"path":"/reference/nv_convert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Tensor to Different Data Type — nv_convert","text":"operand (nv_tensor) Operand. dtype (character(1) | stablehlo::TensorDataType) Data type.","code":""},{"path":"/reference/nv_convert.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Tensor to Different Data Type — nv_convert","text":"nv_tensor","code":""},{"path":"/reference/nv_dtype.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a TensorDataType — nv_dtype","title":"Create a TensorDataType — nv_dtype","text":"Create stablehlo::TensorDataType.","code":""},{"path":"/reference/nv_dtype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a TensorDataType — nv_dtype","text":"","code":"nv_dtype(x)"},{"path":"/reference/nv_dtype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a TensorDataType — nv_dtype","text":"x () Object convertible stablehlo::TensorDataType (via stablehlo::as_dtype)","code":""},{"path":"/reference/nv_dtype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a TensorDataType — nv_dtype","text":"stablehlo::TensorDataType","code":""},{"path":"/reference/nv_matmul.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix Multiplication — nv_matmul","title":"Matrix Multiplication — nv_matmul","text":"Matrix multiplication two tensors.","code":""},{"path":"/reference/nv_matmul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix Multiplication — nv_matmul","text":"","code":"nv_matmul(lhs, rhs)"},{"path":"/reference/nv_matmul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix Multiplication — nv_matmul","text":"lhs (nv_tensor) rhs (nv_tensor)","code":""},{"path":"/reference/nv_matmul.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix Multiplication — nv_matmul","text":"nv_tensor","code":""},{"path":"/reference/nv_matmul.html","id":"shapes","dir":"Reference","previous_headings":"","what":"Shapes","title":"Matrix Multiplication — nv_matmul","text":"lhs: (b1, ..., bk, m, n) rhs: (b1, ..., bk, n, p) output: (b1, ..., bk, m, p)","code":""},{"path":"/reference/nv_matmul.html","id":"broadcasting","dir":"Reference","previous_headings":"","what":"Broadcasting","title":"Matrix Multiplication — nv_matmul","text":"dimensions last two broadcasted.","code":""},{"path":"/reference/nv_reduce_ops.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduction Operators — nv_reduce_ops","title":"Reduction Operators — nv_reduce_ops","text":"Reduce tensor along specified dimensions.","code":""},{"path":"/reference/nv_reduce_ops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduction Operators — nv_reduce_ops","text":"","code":"nv_reduce_sum(operand, dims, drop = TRUE)  nv_reduce_mean(operand, dims, drop = TRUE)  nv_reduce_prod(operand, dims, drop = TRUE)  nv_reduce_max(operand, dims, drop = TRUE)  nv_reduce_min(operand, dims, drop = TRUE)  nv_reduce_any(operand, dims, drop = TRUE)  nv_reduce_all(operand, dims, drop = TRUE)"},{"path":"/reference/nv_reduce_ops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduction Operators — nv_reduce_ops","text":"operand (nv_tensor) Operand. dims (integer()) Dimensions reduce. drop (logical(1)) Whether drop reduced dimensions.","code":""},{"path":"/reference/nv_reduce_ops.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduction Operators — nv_reduce_ops","text":"nv_tensor","code":""},{"path":"/reference/nv_reshape.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape — nv_reshape","title":"Reshape — nv_reshape","text":"Reshape tensor. Note row-major order used, differs R's column-major order.","code":""},{"path":"/reference/nv_reshape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape — nv_reshape","text":"","code":"nv_reshape(operand, shape)"},{"path":"/reference/nv_reshape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape — nv_reshape","text":"operand (nv_tensor) Operand. shape (integer()) new shape.","code":""},{"path":"/reference/nv_reshape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape — nv_reshape","text":"nv_tensor","code":""},{"path":"/reference/nv_tensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Tensor — nv_tensor","title":"Tensor — nv_tensor","text":"Create tensor.","code":""},{"path":"/reference/nv_tensor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tensor — nv_tensor","text":"","code":"nv_tensor(data, dtype = NULL, device = NULL, shape = NULL)  nv_scalar(data, dtype = NULL, device = NULL)  nv_empty(dtype, shape, device = NULL)"},{"path":"/reference/nv_tensor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tensor — nv_tensor","text":"data () Object convertible PJRTBuffer. dtype (NULL | character(1) | stablehlo::TensorDataType) One pred, i8, i16, i32, i64, ui8, ui16, ui32, ui64, f32, f64 stablehlo::TensorDataType. default (NULL) uses f32 numeric data, i32 integer data, pred logical data. device (NULL | character(1) | PJRTDevice) platform name tensor (\"cpu\", \"cuda\", \"metal\"). Default use CPU, unless data already PJRTBuffer. can change default setting PJRT_PLATFORM environment variable. shape (NULL | integer()) Shape. default (NULL) infer data possible. Note nv_tensor interprets length 1 vectors shape (1). create \"scalar\" dimension (), use nv_scalar.","code":""},{"path":"/reference/nv_tensor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tensor — nv_tensor","text":"(AnvilTensor)","code":""},{"path":"/reference/nv_tensor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tensor — nv_tensor","text":"Internally calls pjrt_buffer.","code":""},{"path":"/reference/nv_transpose.html","id":null,"dir":"Reference","previous_headings":"","what":"Transpose — nv_transpose","title":"Transpose — nv_transpose","text":"Transpose tensor.","code":""},{"path":"/reference/nv_transpose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transpose — nv_transpose","text":"","code":"nv_transpose(x, permutation = NULL)  # S3 method for class '`anvil::Box`' t(x)"},{"path":"/reference/nv_transpose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transpose — nv_transpose","text":"x (nv_tensor) permutation (integer() | NULl) Permutation dimensions. NULL (default), reverses dimensions.","code":""},{"path":"/reference/nv_transpose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transpose — nv_transpose","text":"nv_tensor","code":""},{"path":"/reference/nv_unary_ops.html","id":null,"dir":"Reference","previous_headings":"","what":"Unary Operations — nv_unary_ops","title":"Unary Operations — nv_unary_ops","text":"Unary operations tensors.","code":""},{"path":"/reference/nv_unary_ops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unary Operations — nv_unary_ops","text":"","code":"nv_neg(operand)  nv_abs(operand)  nv_sqrt(operand)  nv_rsqrt(operand)  nv_log(operand)  nv_tanh(operand)  nv_tan(operand)  nv_floor(operand)  nv_ceil(operand)  nv_sign(operand)  nv_exp(operand)  nv_round(operand, method = \"nearest_even\")"},{"path":"/reference/nv_unary_ops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unary Operations — nv_unary_ops","text":"operand (nv_tensor) Operand. method (character(1)) Method use rounding. Either \"nearest_even\" (default) \"afz\" (away zero).","code":""},{"path":"/reference/nv_unary_ops.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unary Operations — nv_unary_ops","text":"nv_tensor","code":""},{"path":"/reference/platform.html","id":null,"dir":"Reference","previous_headings":"","what":"Platform — platform","title":"Platform — platform","text":"Get platform tensor-like object.","code":""},{"path":"/reference/platform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Platform — platform","text":"","code":"platform(x, ...)"},{"path":"/reference/platform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Platform — platform","text":"x () tensor. ... () Additional argument (unused).","code":""},{"path":"/reference/platform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Platform — platform","text":"(character(1))","code":""},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. stablehlo is_dtype tengen as_array, as_raw, device, ndims, shape","code":""},{"path":"/reference/stablehlo.html","id":null,"dir":"Reference","previous_headings":"","what":"Lower a function to StableHLO — stablehlo","title":"Lower a function to StableHLO — stablehlo","text":"Immediately lower flattened function StableHLO Func object.","code":""},{"path":"/reference/stablehlo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lower a function to StableHLO — stablehlo","text":"","code":"stablehlo(.f, .avals)"},{"path":"/reference/stablehlo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lower a function to StableHLO — stablehlo","text":".f (function) Flattened function lower. .avals (list()) List flattened abstract values (avals) function arguments. ShapedTensors traced (wrapped HloBox), values passed -(static).","code":""},{"path":"/reference/stablehlo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lower a function to StableHLO — stablehlo","text":"(list) elements: func: StableHLO Func object out_tree: output tree structure","code":""}]
