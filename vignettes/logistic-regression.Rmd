---
title: "Logistic Regression"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Logistic Regression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

In this vignette, we will implement logistic regression from scratch using {anvil}.
Logistic regression is a fundamental algorithm for binary classification, and implementing it showcases core {anvil} features like automatic differentiation and JIT compilation.

## The Problem

Logistic regression models the probability that an observation belongs to a particular class.
Given a feature matrix $X$ and a weight vector $\beta$, the predicted probability is:

$$P(y = 1 | X) = \sigma(X \beta + \alpha)$$

where $\sigma$ is the sigmoid function $\sigma(z) = \frac{1}{1 + e^{-z}}$ and $\alpha$ is the bias term.

In practice, logistic regression is typically fitted using Iteratively Reweighted Least Squares (IRLS), which is a form of Newton's method.
This is the algorithm used by R's `glm()` function.
IRLS requires solving a weighted least squares problem at each iteration, which involves matrix inversion or decomposition (e.g., Cholesky or QR).
In this vignette, we instead use gradient descent for didactic purposes, as it allows us to showcase {anvil}'s automatic differentiation capabilities.

## Simulating Data

Let's start by generating some synthetic data for binary classification.
We'll create two clusters of points that are linearly separable.

```{r}
library(anvil)
set.seed(42)

n <- 200
p <- 2

X_class0 <- matrix(rnorm(n * p, mean = -1), ncol = p)
X_class1 <- matrix(rnorm(n * p, mean = 1), ncol = p)
X <- rbind(X_class0, X_class1)
y <- c(rep(0, n), rep(1, n))

shuffle <- sample(2 * n)
X <- X[shuffle, ]
y <- y[shuffle]
```

We can visualize the data to see the two classes.

```{r, echo = FALSE, fig.width = 6, fig.height = 5}
plot(X[, 1], X[, 2], col = ifelse(y == 1, "blue", "red"), pch = 19,
     xlab = "Feature 1", ylab = "Feature 2", main = "Binary Classification Data")
legend("topright", legend = c("Class 0", "Class 1"), col = c("red", "blue"), pch = 19)
```

Now we convert the data to `AnvilTensor`s.

```{r}
X_tensor <- nv_tensor(X, dtype = "f32")
y_tensor <- nv_tensor(y, dtype = "f32", shape = c(2 * n, 1L))
```

## Defining the Model

The logistic regression model consists of computing the linear combination of features and then applying the sigmoid function.
In {anvil}, the sigmoid function is available via `nv_logistic()`.

```{r}
predict_proba <- function(X, beta, alpha) {
  logits <- X %*% beta + alpha
  nv_logistic(logits)
}
```

## The Loss Function

For binary classification, we use the binary cross-entropy loss:

$$\mathcal{L} = -\frac{1}{n} \sum_{i=1}^{n} \left[ y_i \log(p_i) + (1 - y_i) \log(1 - p_i) \right]$$

We need to be careful with numerical stability when computing the logarithm of probabilities close to 0 or 1.
We'll add a small epsilon to avoid taking the log of exactly 0.

```{r}
binary_cross_entropy <- function(y_true, y_pred) {
  eps <- 1e-7
  y_pred_clipped <- nv_clamp(eps, y_pred, 1 - eps)
  loss <- -(y_true * log(y_pred_clipped) + (1 - y_true) * log(1 - y_pred_clipped))
  mean(loss)
}
```

We combine the prediction and loss computation into a single function.

```{r}
model_loss <- function(X, y, beta, alpha) {
  y_pred <- predict_proba(X, beta, alpha)
  binary_cross_entropy(y, y_pred)
}
```

## Computing Gradients

Using {anvil}'s automatic differentiation, we can obtain the gradients of the loss with respect to the model parameters.

```{r}
model_loss_grad <- gradient(model_loss, wrt = c("beta", "alpha"))
```

## Training with Gradient Descent

Now we can implement the training loop.
We initialize the weights randomly and iteratively update them using gradient descent.

```{r}
update_weights <- function(X, y, beta, alpha, lr) {
  grads <- model_loss_grad(X, y, beta, alpha)
  beta_new <- beta - lr * grads$beta
  alpha_new <- alpha - lr * grads$alpha
  list(beta = beta_new, alpha = alpha_new)
}
```

We JIT-compile the update function for efficiency.

```{r}
update_weights_jit <- jit(update_weights, static = "lr")
```

Let's also create a JIT-compiled function to compute the loss so we can track training progress.

```{r}
compute_loss <- jit(model_loss)
```

Now we initialize the parameters and run the training loop.

```{r}
beta <- nv_tensor(rnorm(p), dtype = "f32", shape = c(p, 1L))
alpha <- nv_scalar(0, dtype = "f32")

n_epochs <- 100
lr <- 0.5
losses <- numeric(n_epochs)

for (epoch in seq_len(n_epochs)) {
  loss <- compute_loss(X_tensor, y_tensor, beta, alpha)
  losses[epoch] <- as_array(loss)

  weights <- update_weights_jit(X_tensor, y_tensor, beta, alpha, lr)
  beta <- weights$beta
  alpha <- weights$alpha
}
```

We can visualize the training progress by plotting the loss over epochs.

```{r, echo = FALSE, fig.width = 6, fig.height = 4}
plot(seq_len(n_epochs), losses, type = "l", col = "blue", lwd = 2,
     xlab = "Epoch", ylab = "Loss", main = "Training Loss")
```

## Making Predictions

With the trained model, we can make predictions on new data.
We classify observations based on whether the predicted probability exceeds 0.5.

```{r}
predict_class <- function(X, beta, alpha) {
  proba <- predict_proba(X, beta, alpha)
  nv_ge(proba, 0.5)
}

predict_class_jit <- jit(predict_class)
```

Let's evaluate the model's accuracy on the training data.

```{r}
predictions <- predict_class_jit(X_tensor, beta, alpha)
accuracy <- mean(as_array(predictions) == y)
accuracy
```

## Visualizing the Decision Boundary

We can visualize the learned decision boundary by plotting the line where the predicted probability equals 0.5.
This occurs when $X \beta + \alpha = 0$.

```{r, echo = FALSE, fig.width = 6, fig.height = 5}
beta_r <- as_array(beta)
alpha_r <- as_array(alpha)

plot(X[, 1], X[, 2], col = ifelse(y == 1, "blue", "red"), pch = 19,
     xlab = "Feature 1", ylab = "Feature 2", main = "Decision Boundary")

x1_range <- seq(min(X[, 1]) - 0.5, max(X[, 1]) + 0.5, length.out = 100)
x2_boundary <- -(beta_r[1] * x1_range + alpha_r) / beta_r[2]
lines(x1_range, x2_boundary, col = "black", lwd = 2)
legend("topright", legend = c("Class 0", "Class 1", "Boundary"),
       col = c("red", "blue", "black"), pch = c(19, 19, NA), lty = c(NA, NA, 1), lwd = 2)
```

## Using nv_while for Training

As discussed in the "Get Started" vignette, repeatedly calling a JIT-compiled function from R has some overhead.
For more efficient training, we can use `nv_while()` to keep the entire training loop within a single compiled function.

```{r}
train_loop <- jit(function(X, y, beta, alpha, n_epochs, lr) {
  nv_while(
    list(beta = beta, alpha = alpha, epoch = nv_scalar(0L)),
    \(beta, alpha, epoch) epoch < n_epochs,
    \(beta, alpha, epoch) {
      grads <- model_loss_grad(X, y, beta, alpha)
      list(
        beta = beta - lr * grads$beta,
        alpha = alpha - lr * grads$alpha,
        epoch = epoch + 1L
      )
    }
  )
})
```

We can now train the model with a single function call.

```{r}
beta_init <- nv_tensor(rnorm(p), dtype = "f32", shape = c(p, 1L))
alpha_init <- nv_scalar(0, dtype = "f32")

result <- train_loop(
  X_tensor, y_tensor,
  beta_init, alpha_init,
  nv_scalar(100L),
  nv_scalar(0.5)
)

result$beta
result$alpha
```

This approach compiles the entire training procedure into a single XLA executable, eliminating the overhead of switching between R and the XLA runtime on each iteration.
